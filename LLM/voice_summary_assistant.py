# voice_summary_assistant.py
import ollama
import websocket
import whisper
import sounddevice as sd
import numpy as np
import paho.mqtt.client as mqtt # MQTT ì¶”ê°€
import json
import pyttsx3 # TTS ì¶”ê°€
import threading # MQTT ìˆ˜ì‹ ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì¶”ê°€
import io, sys
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8') # ì¸ì½”ë”© ì„¤ì •

# --- ì„¤ì • ---
SAMPLE_RATE = 16000
DURATION = 5
WHISPER_MODEL = "base"
OLLAMA_MODEL = "phi3:mini"
MQTT_BROKER = "localhost"
MQTT_PORT = 1883
MQTT_SENSOR_TOPIC = "factory/sensors"

# --- LLM í”„ë¡¬í”„íŠ¸ ---
SUMMARY_SYSTEM_PROMPT = """
You are a helpful AI assistant for a factory manager.
Analyze sensor data and provide a brief, human-readable summary in Korean.
Your response MUST be ONLY in Korean and follow the given format exactly.

---
### EXAMPLE
User Input: Final Temp: 55.2, Max Temp: 58.1, Max Vibration: 1.8
Your Correct Response:
- ìµœì¢… ì˜¨ë„: 55.2 Â°C
- ìµœê³  ì˜¨ë„: 58.1 Â°C
- íŠ¹ì´ì‚¬í•­: ì˜¨ë„ê°€ 50ë„ë¥¼ ì´ˆê³¼í–ˆìœ¼ë©°, ì§„ë™ ìˆ˜ì¹˜ê°€ 1.5ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.
---
Now, create a report for the following data.
"""

# --- ì „ì—­ ë³€ìˆ˜ ---
sensor_data_history = [] # MQTT ë°ì´í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸
tts_engine = pyttsx3.init() # TTS ì—”ì§„ ì´ˆê¸°í™”

# --- í•¨ìˆ˜ ì •ì˜ ---
def speak(text):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜"""
    print(f"ğŸ”Š AI ë‹µë³€: {text}")
    tts_engine.say(text)
    tts_engine.runAndWait()

def summarize_data():
    """ëˆ„ì ëœ ë°ì´í„°ë¥¼ LLMìœ¼ë¡œ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜"""
    if not sensor_data_history:
        return "ìš”ì•½í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    temperatures = []
    vibrations = []
    for msg in sensor_data_history:
        try:
            data = json.loads(msg)
            if 'temperature' in data: temperatures.append(data['temperature'])
            if 'vibration' in data: vibrations.append(data['vibration'])
        except json.JSONDecodeError: continue

    if not temperatures: return "ìœ íš¨í•œ ì˜¨ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    final_temp = temperatures[-1]; max_temp = max(temperatures)
    max_vib = max(vibrations) if vibrations else 0
    data_for_llm = f"Final Temp: {final_temp}, Max Temp: {max_temp}, Max Vibration: {max_vib}"

    try:
        response = ollama.chat( model=OLLAMA_MODEL, messages=[ {'role': 'system', 'content': SUMMARY_SYSTEM_PROMPT}, {'role': 'user', 'content': data_for_llm} ] )
        return response['message']['content']
    except Exception as e:
        return f"LLM ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# --- MQTT ì½œë°± í•¨ìˆ˜ ---
def on_connect(client, userdata, flags, rc):
    if rc == 0:
        print("MQTT ë¸Œë¡œì»¤ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¼ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•©ë‹ˆë‹¤...")
        client.subscribe(MQTT_SENSOR_TOPIC)
    else:
        print(f"MQTT ì—°ê²° ì‹¤íŒ¨ (ì½”ë“œ: {rc})")

def on_message(client, userdata, msg):
    """MQTT ë©”ì‹œì§€ ìˆ˜ì‹  ì‹œ ë°ì´í„° ì €ì¥"""
    payload = msg.payload.decode('utf-8')
    print(f"Received MQTT: {payload}") # ë””ë²„ê¹…ìš© ë¡œê·¸
    sensor_data_history.append(payload)
    # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•´ ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ (ì˜ˆ: ìµœê·¼ 100ê°œë§Œ ì €ì¥)
    if len(sensor_data_history) > 100:
        del sensor_data_history[0]

# --- MQTT í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ë° ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ---
mqtt_client = mqtt.Client()
mqtt_client.on_connect = on_connect
mqtt_client.on_message = on_message
try:
    mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)
    # MQTT í´ë¼ì´ì–¸íŠ¸ë¥¼ ë³„ë„ì˜ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ì—¬ ë©”ì¸ í”„ë¡œê·¸ë¨(ìŒì„±ì¸ì‹)ì„ ë°©í•´í•˜ì§€ ì•Šë„ë¡ í•¨
    mqtt_thread = threading.Thread(target=mqtt_client.loop_forever)
    mqtt_thread.daemon = True # ë©”ì¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ í•¨ê»˜ ì¢…ë£Œë˜ë„ë¡ ì„¤ì •
    mqtt_thread.start()
except Exception as e:
    print(f"MQTT ì—°ê²° ì‹œë„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- Whisper ëª¨ë¸ ë¡œë”© ---
print("Whisper ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤...")
asr_model = whisper.load_model(WHISPER_MODEL)
print("AI ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- ë©”ì¸ ë£¨í”„ (ìŒì„± ëª…ë ¹ ì²˜ë¦¬) ---
try:
    while True:
        input("\nğŸ™ï¸ ì—”í„° í‚¤ë¥¼ ëˆ„ë¥´ê³  5ì´ˆê°„ ëª…ë ¹ì„ ë§ì”€í•˜ì„¸ìš”...")
        print("ë“£ëŠ” ì¤‘...")
        recording = sd.rec(int(DURATION * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1)
        sd.wait()
        print("ìŒì„± ì¸ì‹ ì¤‘...")
        audio_data = recording.flatten().astype(np.float32)
        transcribed_result = asr_model.transcribe(audio_data, language='ko', fp16=False)
        user_command = transcribed_result["text"].strip().lower() # ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ

        if not user_command:
            print("ì¸ì‹ëœ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        print(f"ğŸ‘¤ ë‹¹ì‹ ì˜ ëª…ë ¹: {user_command}")

        # --- ëª…ë ¹ ë¶„ì„ ë° ì‹¤í–‰ ---
        if "ìš”ì•½" in user_command or "ìƒíƒœ" in user_command or "ë³´ê³ " in user_command:
            # 'ìš”ì•½' ê´€ë ¨ ëª…ë ¹ ì²˜ë¦¬
            summary_text = summarize_data()
            speak(summary_text) # ìš”ì•½ ê²°ê³¼ë¥¼ ìŒì„±ìœ¼ë¡œ ì¶œë ¥
            
        else:
            speak("ì£„ì†¡í•©ë‹ˆë‹¤. ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 'ìƒíƒœ ìš”ì•½' ë˜ëŠ” 'ë³´ê³ í•´ ì¤˜' ë¼ê³  ë§ì”€í•´ ë³´ì„¸ìš”.")

except KeyboardInterrupt:
    print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    if mqtt_client.is_connected():
        mqtt_client.disconnect()